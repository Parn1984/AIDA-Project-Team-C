{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_exploration.data_ex import import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>2845</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>2301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>1616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>2510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>408</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>235.7</td>\n",
       "      <td>127</td>\n",
       "      <td>40.07</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>18.96</td>\n",
       "      <td>297.5</td>\n",
       "      <td>116</td>\n",
       "      <td>13.39</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>49</td>\n",
       "      <td>152</td>\n",
       "      <td>415</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184.2</td>\n",
       "      <td>90</td>\n",
       "      <td>31.31</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>21.83</td>\n",
       "      <td>213.6</td>\n",
       "      <td>113</td>\n",
       "      <td>9.61</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>415</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140.6</td>\n",
       "      <td>89</td>\n",
       "      <td>23.90</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>14.69</td>\n",
       "      <td>212.4</td>\n",
       "      <td>97</td>\n",
       "      <td>9.56</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>7</td>\n",
       "      <td>109</td>\n",
       "      <td>510</td>\n",
       "      <td>3471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188.8</td>\n",
       "      <td>67</td>\n",
       "      <td>32.10</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.59</td>\n",
       "      <td>224.4</td>\n",
       "      <td>89</td>\n",
       "      <td>10.10</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>46</td>\n",
       "      <td>86</td>\n",
       "      <td>415</td>\n",
       "      <td>2412</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>129.4</td>\n",
       "      <td>102</td>\n",
       "      <td>22.00</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>22.70</td>\n",
       "      <td>154.8</td>\n",
       "      <td>100</td>\n",
       "      <td>6.97</td>\n",
       "      <td>9.3</td>\n",
       "      <td>16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  account_length  area_code  phone_number  international_plan  \\\n",
       "0        16             128        415          2845                   0   \n",
       "1        35             107        415          2301                   0   \n",
       "2        31             137        415          1616                   0   \n",
       "3        35              84        408          2510                   1   \n",
       "4        36              75        415           155                   1   \n",
       "...     ...             ...        ...           ...                 ...   \n",
       "4995     11              50        408          2000                   0   \n",
       "4996     49             152        415           394                   0   \n",
       "4997      7              61        415           313                   0   \n",
       "4998      7             109        510          3471                   0   \n",
       "4999     46              86        415          2412                   0   \n",
       "\n",
       "      voice_mail_plan  number_vmail_messages  total_day_minutes  \\\n",
       "0                   1                     25              265.1   \n",
       "1                   1                     26              161.6   \n",
       "2                   0                      0              243.4   \n",
       "3                   0                      0              299.4   \n",
       "4                   0                      0              166.7   \n",
       "...               ...                    ...                ...   \n",
       "4995                1                     40              235.7   \n",
       "4996                0                      0              184.2   \n",
       "4997                0                      0              140.6   \n",
       "4998                0                      0              188.8   \n",
       "4999                1                     34              129.4   \n",
       "\n",
       "      total_day_calls  total_day_charge  ...  total_eve_calls  \\\n",
       "0                 110             45.07  ...               99   \n",
       "1                 123             27.47  ...              103   \n",
       "2                 114             41.38  ...              110   \n",
       "3                  71             50.90  ...               88   \n",
       "4                 113             28.34  ...              122   \n",
       "...               ...               ...  ...              ...   \n",
       "4995              127             40.07  ...              126   \n",
       "4996               90             31.31  ...               73   \n",
       "4997               89             23.90  ...              128   \n",
       "4998               67             32.10  ...               92   \n",
       "4999              102             22.00  ...              104   \n",
       "\n",
       "      total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "0                16.78                244.7                 91   \n",
       "1                16.62                254.4                103   \n",
       "2                10.30                162.6                104   \n",
       "3                 5.26                196.9                 89   \n",
       "4                12.61                186.9                121   \n",
       "...                ...                  ...                ...   \n",
       "4995             18.96                297.5                116   \n",
       "4996             21.83                213.6                113   \n",
       "4997             14.69                212.4                 97   \n",
       "4998             14.59                224.4                 89   \n",
       "4999             22.70                154.8                100   \n",
       "\n",
       "      total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "0                  11.01                10.0                 3   \n",
       "1                  11.45                13.7                 3   \n",
       "2                   7.32                12.2                 5   \n",
       "3                   8.86                 6.6                 7   \n",
       "4                   8.41                10.1                 3   \n",
       "...                  ...                 ...               ...   \n",
       "4995               13.39                 9.9                 5   \n",
       "4996                9.61                14.7                 2   \n",
       "4997                9.56                13.6                 4   \n",
       "4998               10.10                 8.5                 6   \n",
       "4999                6.97                 9.3                16   \n",
       "\n",
       "      total_intl_charge  number_customer_service_calls  class  \n",
       "0                  2.70                              1      0  \n",
       "1                  3.70                              1      0  \n",
       "2                  3.29                              0      0  \n",
       "3                  1.78                              2      0  \n",
       "4                  2.73                              3      0  \n",
       "...                 ...                            ...    ...  \n",
       "4995               2.67                              2      0  \n",
       "4996               3.97                              3      1  \n",
       "4997               3.67                              1      0  \n",
       "4998               2.30                              0      0  \n",
       "4999               2.51                              0      0  \n",
       "\n",
       "[5000 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = import_data('data/churn.csv')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4000, 20)\n",
      "y_train shape: (4000,)\n",
      "X_test shape: (1000, 20)\n",
      "y_test shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "y_column = 'class'\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop([y_column], axis=1)\n",
    "y = data[y_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.800)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                672       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,229\n",
      "Trainable params: 1,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = len(X_train.columns)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential() # model instance\n",
    "\n",
    "# accuracy: 0.8890\n",
    "#model.add(tf.keras.layers.Dense(20, input_shape=(input_shape,), activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "# accuracy: 0.915\n",
    "#model.add(tf.keras.layers.Dense(20, input_shape=(input_shape,), activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "#model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "# accuracy: xx\n",
    "model.add(tf.keras.layers.Dense(20, input_shape=(input_shape,), activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(4, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) # output layer with 10 classes to clasify\n",
    "model.summary() # architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.002),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 35.7787 - accuracy: 0.7694 - val_loss: 0.6211 - val_accuracy: 0.8737\n",
      "Epoch 2/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7535 - accuracy: 0.8494 - val_loss: 0.5857 - val_accuracy: 0.8737\n",
      "Epoch 3/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8530 - accuracy: 0.8512 - val_loss: 0.5114 - val_accuracy: 0.8737\n",
      "Epoch 4/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.8525 - val_loss: 0.4791 - val_accuracy: 0.8737\n",
      "Epoch 5/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.8531 - val_loss: 0.4434 - val_accuracy: 0.8737\n",
      "Epoch 6/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8541 - val_loss: 0.4558 - val_accuracy: 0.8737\n",
      "Epoch 7/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.8544 - val_loss: 0.3992 - val_accuracy: 0.8737\n",
      "Epoch 8/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8534 - val_loss: 0.4383 - val_accuracy: 0.8737\n",
      "Epoch 9/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8534 - val_loss: 0.4186 - val_accuracy: 0.8737\n",
      "Epoch 10/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8547 - val_loss: 0.4205 - val_accuracy: 0.8737\n",
      "Epoch 11/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8541 - val_loss: 0.3992 - val_accuracy: 0.8737\n",
      "Epoch 12/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8541 - val_loss: 0.4028 - val_accuracy: 0.8737\n",
      "Epoch 13/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8541 - val_loss: 0.3953 - val_accuracy: 0.8737\n",
      "Epoch 14/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8531 - val_loss: 0.3902 - val_accuracy: 0.8737\n",
      "Epoch 15/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8544 - val_loss: 0.3923 - val_accuracy: 0.8737\n",
      "Epoch 16/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8544 - val_loss: 0.3872 - val_accuracy: 0.8737\n",
      "Epoch 17/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8547 - val_loss: 0.3862 - val_accuracy: 0.8737\n",
      "Epoch 18/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.8544 - val_loss: 0.3846 - val_accuracy: 0.8737\n",
      "Epoch 19/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8547 - val_loss: 0.3841 - val_accuracy: 0.8737\n",
      "Epoch 20/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8541 - val_loss: 0.3831 - val_accuracy: 0.8737\n",
      "Epoch 21/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8547 - val_loss: 0.3826 - val_accuracy: 0.8737\n",
      "Epoch 22/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8547 - val_loss: 0.3823 - val_accuracy: 0.8737\n",
      "Epoch 23/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8544 - val_loss: 0.3818 - val_accuracy: 0.8737\n",
      "Epoch 24/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8547 - val_loss: 0.3813 - val_accuracy: 0.8737\n",
      "Epoch 25/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8547 - val_loss: 0.3811 - val_accuracy: 0.8737\n",
      "Epoch 26/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8547 - val_loss: 0.3810 - val_accuracy: 0.8737\n",
      "Epoch 27/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8544 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 28/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 29/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8544 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 30/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 31/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 32/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8547 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 33/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 34/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8547 - val_loss: 0.3805 - val_accuracy: 0.8737\n",
      "Epoch 35/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 36/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8544 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 37/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8547 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 38/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 39/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8544 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 40/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 41/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 42/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8544 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 43/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 44/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 45/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8544 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 46/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8541 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 47/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 48/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 49/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 50/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 51/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 52/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 53/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 54/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 55/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 56/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8544 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 57/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 59/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 60/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 61/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8544 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 62/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 63/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 64/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 65/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 66/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 67/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 68/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 69/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 70/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 71/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 72/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 73/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 74/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 75/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 76/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 77/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 78/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 79/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 80/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8544 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 81/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 82/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 83/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 84/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 85/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 86/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 87/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 88/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 89/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 90/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 91/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 92/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 93/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 94/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 95/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 96/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8544 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 97/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 98/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 99/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 100/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 101/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 102/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 103/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 104/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 105/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 106/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 107/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 108/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 109/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 110/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 111/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8544 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 112/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 113/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 114/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 116/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 117/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 118/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 119/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 120/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 121/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 122/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 123/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 124/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 125/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 126/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 127/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 128/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 129/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 130/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 131/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 132/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 133/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 134/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 135/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 136/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 137/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 138/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 139/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 140/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 141/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 142/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8544 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 143/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 144/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 145/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 146/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 147/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 148/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 149/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 150/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 151/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 152/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 153/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 154/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 155/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 156/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 157/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 158/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 159/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3809 - val_accuracy: 0.8737\n",
      "Epoch 160/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 161/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 162/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 163/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 164/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 165/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 166/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 167/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 168/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 169/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 170/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 172/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 173/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 174/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 175/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 176/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 177/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 178/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 179/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 180/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 181/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8737\n",
      "Epoch 182/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 0.3806 - val_accuracy: 0.8737\n",
      "Epoch 183/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 184/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 185/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 186/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.3807 - val_accuracy: 0.8737\n",
      "Epoch 187/300\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.2123 - accuracy: 0.9688"
     ]
    }
   ],
   "source": [
    "epo = 300\n",
    "history = model.fit(X_train, y_train, epochs=epo, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'], label='train set accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation set accuracy')\n",
    "plt.xticks(range(epo))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = np.where(y_pred<=0.5, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "data = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=['no churn', 'churn'], index=['no churn', 'churn'])\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.set(font_scale=1.4)  # for label size\n",
    "sns.heatmap(df_cm, cmap='RdYlGn', annot=True, annot_kws={\"size\": 14}, fmt='d')\n",
    "plt.title(\"Confusion Matrix\", fontweight='bold')\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
